{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Global"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_saved_name=\"model_weights.ckpt\"\n","data_dir=r'C:\\Users\\ossia\\Documents\\GitHub\\MagLearn-Bristol-2\\Single Pipeline\\preprocessed_training_dataset_3'"]},{"cell_type":"markdown","metadata":{},"source":["## processing..."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399},"executionInfo":{"elapsed":7189,"status":"error","timestamp":1691832850627,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"},"user_tz":-60},"id":"Gz-wXmweGAMO","outputId":"b7d0e8d8-c98e-4909-ce20-f170a8ddaefa"},"outputs":[],"source":["import numpy as np\n","import torch\n","import os\n","import torch.optim as optim\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","import matplotlib.pyplot as plt\n","\n","import NW_LSTM\n","import NN_DataLoader\n","\n","# Check if CUDA is available and if so, set the device to GPU\n","device = torch.device(\"cpu\")\n","print(\"Device using \", device)\n","\n","class MyDataset(Dataset):\n","\n","    def __init__(self, x_data, y_data):\n","        self.x_data = torch.tensor(x_data, dtype=torch.float32)\n","        self.y_data = torch.tensor(y_data, dtype=torch.float32)\n","\n","    def __len__(self):\n","        return len(self.x_data)\n","\n","    def __getitem__(self, idx):\n","        return self.x_data[idx], self.y_data[idx]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize the list of materials to validate\n","materials = []\n","\n","# Check if data_dir is a real directory\n","if os.path.exists(data_dir) and os.path.isdir(data_dir):\n","    # Get the list of materials in the data_dir folder\n","    subfolders = [item for item in os.listdir(data_dir)\n","                  if os.path.isdir(os.path.join(data_dir, item))]\n","\n","    # Check if there are any subfolders\n","    if subfolders:\n","        # Save the names of the subfolders to the materials list\n","        materials = subfolders\n","    else:\n","        print(\"No material datasets found in directory specified by data_dir, preprocessed (normalised, down sampled and split) training materials should be saved into subfolders within this directory, where each subfolder is the name of a training material.\")\n","else:\n","    print(\"Directory specified by data_dir does not seem to exist, please ensure data_dir specifies a folder containing subfolders of processed training datasets for each material.\")\n","\n","# Print the list of training materials if they exist\n","if materials:\n","    print(\"Identified training data for materials:\", materials)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1691832850628,"user":{"displayName":"Lizhong Zhang","userId":"15095891074797676359"},"user_tz":-60},"id":"2l-kYSquGAMR"},"outputs":[],"source":["import Maglib\n","\n","for mat in materials:\n","    material_dir = os.path.join(data_dir, mat)\n","    magData = Maglib.MagLoader(os.path.join(material_dir, 'test.mat'))\n","\n","    # Instantiate the model with appropriate dimensions\n","    model = NW_LSTM.get_global_model().to(device)\n","    model.load_state_dict(torch.load(os.path.join(material_dir, model_saved_name), map_location=device)) # Load trained material model from .ckpt file\n","\n","    x_data = np.zeros([magData.b.shape[0], magData.b.shape[1], 3])\n","    x_data[:, :, 0] = magData.b\n","    x_data[:, :, 1] = magData.freq\n","    x_data[:, :, 2] = magData.temp\n","\n","    idx = 0\n","    dataNums = magData.freq.shape[0]\n","    # no more than 2000\n","    if(dataNums>2000):dataNums=2000\n","\n","\n","    x_data = x_data[idx:idx + dataNums, :, :]\n","    y_data = magData.loss[idx:idx + dataNums, :]\n","\n","    # Now we can pass a batch of sequences through the model\n","    inputs = torch.tensor(x_data, dtype=torch.float32)\n","\n","    outputs = model(inputs)\n","\n","    total_params = sum(p.numel() for p in model.parameters())\n","\n","    print('Data size ', magData.b.shape[0])\n","    print('model parameters: ', total_params)\n","\n","    # get model performance\n","\n","    # get loss\n","    pred = outputs.detach().numpy()\n","    real = y_data\n","\n","    import linear_std\n","    import MagNet\n","\n","    std_loss = linear_std.linear_std()\n","    std_loss.load(os.path.join(material_dir, \"std_loss.stdd\"))\n","\n","    pred = std_loss.unstd(pred)\n","    real = std_loss.unstd(real)\n","\n","    relv_error = abs(pred - real) / real # Relative absolute error\n","    mean_relv_error = np.mean(relv_error, axis=0)\n","    MagNet.Mag_plot(mat, relv_error, save_path = data_dir)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if(0):\n","    bad_example=[]\n","    good_example=[]\n","    for idx in range(error.shape[0]):\n","        if abs(error[idx])>0.2:\n","            bad_example.append(idx)\n","        elif abs(error[idx])<0.04:\n","            good_example.append(idx)\n","\n","\n","    std_temp= linear_std.linear_std()\n","    std_temp.load(data_dir+r\"\\std_temp.stdd\")\n","\n","    std_freq= linear_std.linear_std()\n","    std_freq.load(dataset_path+r\"\\std_freq.stdd\")\n","\n","\n","    bad_freq=[]\n","    bad_temp=[]\n","\n","    good_freq=[]\n","    good_temp=[]\n","\n","    for idx in bad_example:\n","        bad_freq.append(std_freq.unstd(magData.freq[idx]))\n","        bad_temp.append(std_temp.unstd(magData.temp[idx]))\n","\n","    for idx in good_example:\n","        good_freq.append(std_freq.unstd(magData.freq[idx]))\n","        good_temp.append(std_temp.unstd(magData.temp[idx]))\n","\n","\n","    # plot the distribution of good_freq vs bad_freq\n","    plt.figure()\n","    plt.title(\"error distribution in freq\")\n","    plt.hist(np.array(good_freq),label=\"good\")\n","    plt.hist(np.array(bad_freq),label=\"bad\")\n","    plt.legend()\n","    plt.show()\n","\n","    # plot the distribution of good_temp vs bad_temp\n","    plt.figure()\n","    plt.title(\"error distribution in temp\")\n","    plt.hist(np.array(good_temp),label=\"good\")\n","    plt.hist(np.array(bad_temp),label=\"bad\")\n","    plt.legend()\n","    plt.show()\n","\n","    # plot the distribution of error\n","    drawing=False\n","\n","    if drawing:\n","        for idx in bad_example:\n","            plt.figure()\n","            # using title to show the temp and freq\n","            plt.title('temp: ' + str(std_temp.unstd(magData.temp[idx])) +\n","                    '\\nfreq: ' + str(std_freq.unstd(magData.freq[idx])))\n","\n","            plt.plot(magData.b[idx,:])\n","            plt.show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}

{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1719412608054,"user":{"displayName":"Ossian Sydow Elias","userId":"08221504421133916868"},"user_tz":-60},"id":"i9QSsr_m01VA"},"outputs":[],"source":["import os\n","from os import listdir\n","from os.path import isdir, join\n","import sys"]},{"cell_type":"markdown","metadata":{"id":"XQSzNovNpM1J"},"source":["# Setting Directories"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1719412608584,"user":{"displayName":"Ossian Sydow Elias","userId":"08221504421133916868"},"user_tz":-60},"id":"-vXJJSvfe36c"},"outputs":[],"source":["data_dir = r'C:\\Users\\ossia\\Documents\\GitHub\\MagLearn-Bristol-2\\Single Pipeline'\n","#data_dir = '/content/drive/MyDrive/MagNetDrive'  # If using Colab with Google Drive, set this to the location on Drive containing all the data for this project ie '/MyDrive/MagNetDatastore'"]},{"cell_type":"markdown","metadata":{"id":"gJnpInmX01VF"},"source":["# Setting Environment"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2442,"status":"ok","timestamp":1719412611024,"user":{"displayName":"Ossian Sydow Elias","userId":"08221504421133916868"},"user_tz":-60},"id":"7co6a3y701VF","outputId":"955507e3-21d2-4e41-c87e-138cba26dc89"},"outputs":[{"name":"stdout","output_type":"stream","text":["Running locally.\n"]}],"source":["# Check if the code is running on Google Colab\n","if 'google.colab' in sys.modules:\n","    from google.colab import drive\n","    # Mount Google Drive\n","    drive.mount('/content/drive')\n","    # Set the dataset directory path on Google Drive\n","    data_dir = os.path.join('/content/drive/', data_dir)  # Changes current working directory to Google Drive hosted folder, containing all data and functional scripts\n","    os.chdir(data_dir)\n","    platform = \"colab\"\n","    print(\"Running on Google Colab. Google Drive mounted.\")\n","else:\n","    platform = \"local\"\n","    print(\"Running locally.\")\n"]},{"cell_type":"markdown","metadata":{"id":"AWuEEfZB01VG"},"source":["# Loading Training Materials"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1719412611024,"user":{"displayName":"Ossian Sydow Elias","userId":"08221504421133916868"},"user_tz":-60},"id":"xEI0EcIVuVXp","outputId":"19b67458-8955-4fbb-f140-fab98745746a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Identified training data for materials: ['3C90', '3C94', '3E6', '3F4', '77', '78', 'N27', 'N30', 'N49', 'N87']\n"]}],"source":["# get all folders name in current directory\n","preprocessed_training_dataset_path = os.path.join(data_dir, \"preprocessed_training_dataset\")\n","\n","# Initialize the training_materials list\n","training_materials = []\n","\n","# Check if the \"preprocessed_training_dataset\" folder exists\n","if os.path.exists(preprocessed_training_dataset_path) and os.path.isdir(preprocessed_training_dataset_path):\n","    # Get the list of materials in the \"preprocessed_training_dataset\" folder\n","    subfolders = [item for item in os.listdir(preprocessed_training_dataset_path)\n","                  if os.path.isdir(os.path.join(preprocessed_training_dataset_path, item))]\n","\n","    # Check if there are any subfolders\n","    if subfolders:\n","        # Save the names of the subfolders to the training_materials list\n","        training_materials = subfolders\n","    else:\n","        print(\"No training dataset found in dataset directory, preprocessed (normalised, down sampled and split) training materials should be saved into subfolders within a folder called 'preprocessed_training_dataset', where each subfolder is the name of a training material.\")\n","else:\n","    print(\"No training dataset found in dataset directory, preprocessed (normalised, down sampled and split) training materials should be saved into subfolders within a folder called 'preprocessed_training_dataset', where each subfolder is the name of a training material.\")\n","\n","# Print the list of training materials if they exist\n","if training_materials:\n","    print(\"Identified training data for materials:\", training_materials)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2977,"status":"ok","timestamp":1719412613999,"user":{"displayName":"Ossian Sydow Elias","userId":"08221504421133916868"},"user_tz":-60},"id":"P71KxLw8ElbE","outputId":"4dfbf9e9-886a-43a0-e7aa-78e527d16472"},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA unavailable\n","System using  cpu\n"]}],"source":["import torch\n","\n","gpu_num = 0\n","cuda_ready = False # Track if CUDA hardware acceleration is engaged\n","\n","if torch.cuda.is_available():\n","    cuda_ready = True\n","    print('CUDA available!')\n","    gpu_num = torch.cuda.device_count()\n","    if (gpu_num < 1):\n","        print('GPU unavailable')\n","    else:\n","        print('GPU num: ', gpu_num)  # Print number of GPUs\n","        for gpu in range(gpu_num):\n","            print('GPU type: ', torch.cuda.get_device_name(gpu))  # Print model of GPU\n","            print('GPU memory: {:.2f} Gbyte'.format(\n","                torch.cuda.get_device_properties(gpu).total_memory /\n","                1e9))  # Print total GPU memory\n","else:\n","    cuda_ready = False\n","    print('CUDA unavailable')\n","\n","# Check if CUDA is available and if so, set the device to GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#device = torch.device(\"cpu\")\n","print(\"System using \", device)"]},{"cell_type":"markdown","metadata":{"id":"7HgpdP0B01VH"},"source":["# Model Training\n","First set base material for transfer learning"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":144601,"status":"ok","timestamp":1719412758596,"user":{"displayName":"Ossian Sydow Elias","userId":"08221504421133916868"},"user_tz":-60},"id":"wiuabFEK01VI","outputId":"dc37bf5d-5e39-4c0f-d757-6dd137e85730"},"outputs":[{"name":"stdout","output_type":"stream","text":["Base model used for transfer learning found at: C:\\Users\\ossia\\Documents\\GitHub\\MagLearn-Bristol-2\\Single Pipeline\\preprocessed_training_dataset\\3C90\\model_weights.ckpt\n","Pre-trained model loaded\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[8], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m material \u001b[38;5;129;01min\u001b[39;00m training_materials:\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m material \u001b[38;5;241m!=\u001b[39m base_mat: \u001b[38;5;66;03m# Prevents pretrained base model from being unnesscesarily retrained\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m             train_model(preprocessed_training_dataset_path, material, base_mat, model_saved_name, device, epochs, valid_batch_size, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, load_pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo base model of material \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_mat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found to facilitate transfer learning, program will need to train \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_mat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from scratch before fine-tuning for other materials.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\ossia\\Documents\\GitHub\\MagLearn-Bristol-2\\Single Pipeline\\train_model.py:88\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(preprocessed_training_dataset_path, material, base_mat, model_saved_name, device, epochs, valid_batch_size, verbose, load_pretrained)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (train_inputs, train_targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[0;32m     86\u001b[0m     train_inputs, train_targets \u001b[38;5;241m=\u001b[39m train_inputs\u001b[38;5;241m.\u001b[39mto(device), train_targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 88\u001b[0m     train_outputs \u001b[38;5;241m=\u001b[39m model(train_inputs)\n\u001b[0;32m     89\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(train_outputs, train_targets)\n\u001b[0;32m     91\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[1;32mc:\\Users\\ossia\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\ossia\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\ossia\\Documents\\GitHub\\MagLearn-Bristol-2\\Single Pipeline\\NW_LSTM.py:63\u001b[0m, in \u001b[0;36mLSTMSeq2One.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     61\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc4(out))\n\u001b[0;32m     62\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc5(out))\n\u001b[1;32m---> 63\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc6(out))\n\u001b[0;32m     64\u001b[0m out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc7(out))\n\u001b[0;32m     65\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc8(out)\n","File \u001b[1;32mc:\\Users\\ossia\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\ossia\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\ossia\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:523\u001b[0m, in \u001b[0;36mELU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39melu(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n","File \u001b[1;32mc:\\Users\\ossia\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:1591\u001b[0m, in \u001b[0;36melu\u001b[1;34m(input, alpha, inplace)\u001b[0m\n\u001b[0;32m   1589\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39melu_(\u001b[38;5;28minput\u001b[39m, alpha)\n\u001b[0;32m   1590\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1591\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39melu(\u001b[38;5;28minput\u001b[39m, alpha)\n\u001b[0;32m   1592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["base_mat = \"3C90\" # This is the base material used to facilitate the first stage of transfer learning as described in the paper, material with largest training dataset selected by default, set as '' to train each material from scratch\n","model_saved_name = \"model_weights.ckpt\"\n","\n","# Setting training period approproate for compute available\n","if cuda_ready:\n","    epochs = 500\n","    valid_batch_size = 3000\n","else:\n","    epochs = 20\n","    valid_batch_size = 1000\n","\n","from train_model import train_model\n","\n","if base_mat == '':\n","    print('Transfer learning function disabled, each material will train from zero initial weightings.')\n","    for material in training_materials:\n","        train_model(preprocessed_training_dataset_path, material, base_mat, model_saved_name, device, epochs, valid_batch_size)\n","elif base_mat in training_materials: # If base training material has been found in directory of training materials\n","    base_model_path = os.path.join(preprocessed_training_dataset_path, base_mat, model_saved_name)\n","    if os.path.exists(base_model_path):\n","        print('Base model used for transfer learning found at:', base_model_path)\n","        for material in training_materials:\n","            if material != base_mat: # Prevents pretrained base model from being unnesscesarily retrained\n","                train_model(preprocessed_training_dataset_path, material, base_mat, model_saved_name, device, epochs, valid_batch_size, verbose=False, load_pretrained=True)\n","    else:\n","        print(f\"No base model of material {base_mat} found to facilitate transfer learning, program will need to train {base_mat} from scratch before fine-tuning for other materials.\")\n","        train_model(preprocessed_training_dataset_path, base_mat, base_mat, model_saved_name, device, epochs, valid_batch_size, verbose=True) # Trains base material from scratch before transferring it to remaining materials\n","        for material in training_materials:\n","            if material != base_mat: # Skips retraining base model\n","                train_model(preprocessed_training_dataset_path, material, base_mat, model_saved_name, device, epochs, valid_batch_size, verbose=False, load_pretrained=True) # Trains remaining materials using base model as starting point 'fine tuning'\n","else:\n","    raise RuntimeError(f\"No training data or pretrained model found for material {base_mat}, check that data directory and base material preference is correctly set in beginning of this cell.\")"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}

{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1719412608054,"user":{"displayName":"Ossian Sydow Elias","userId":"08221504421133916868"},"user_tz":-60},"id":"i9QSsr_m01VA"},"outputs":[],"source":["import os\n","from os import listdir\n","from os.path import isdir, join\n","import sys"]},{"cell_type":"markdown","metadata":{"id":"XQSzNovNpM1J"},"source":["# Setting Directories"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1719412608584,"user":{"displayName":"Ossian Sydow Elias","userId":"08221504421133916868"},"user_tz":-60},"id":"-vXJJSvfe36c"},"outputs":[],"source":["data_dir = r'C:\\Users\\ossia\\Documents\\GitHub\\MagLearn-Bristol-2\\Single Pipeline\\preprocessed_training_dataset'\n","#data_dir = 'MyDrive/preprocessed_training_dataset'  # If using Colab with Google Drive, set this to the location on Drive containing processed material training data for this project ie '/MyDrive/MagNetDatastore/preprocessed_training_dataset'\n","working_dir = 'MyDrive/MagNetDrive' # If using Google Colab + Drive, set this to to the Drive folder where this notebook and the support code is located"]},{"cell_type":"markdown","metadata":{"id":"gJnpInmX01VF"},"source":["# Setting Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2442,"status":"ok","timestamp":1719412611024,"user":{"displayName":"Ossian Sydow Elias","userId":"08221504421133916868"},"user_tz":-60},"id":"7co6a3y701VF","outputId":"955507e3-21d2-4e41-c87e-138cba26dc89"},"outputs":[],"source":["# Check if the code is running on Google Colab\n","if 'google.colab' in sys.modules:\n","    from google.colab import drive\n","    # Mount Google Drive\n","    drive.mount('/content/drive')\n","    # Set the dataset directory path on Google Drive\n","    working_dir = os.path.join('/content/drive/', working_dir)  # Changes current working directory to Google Drive hosted folder, containing all data and functional scripts\n","    os.chdir(working_dir)\n","    data_dir = '/content/drive/' + data_dir\n","    platform = \"colab\"\n","    print(\"Running on Google Colab. Google Drive mounted.\")\n","else:\n","    platform = \"local\"\n","    print(\"Running locally.\")\n"]},{"cell_type":"markdown","metadata":{"id":"AWuEEfZB01VG"},"source":["# Loading Training Materials"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1719412611024,"user":{"displayName":"Ossian Sydow Elias","userId":"08221504421133916868"},"user_tz":-60},"id":"xEI0EcIVuVXp","outputId":"19b67458-8955-4fbb-f140-fab98745746a"},"outputs":[],"source":["# Initialize the training_materials list\n","training_materials = []\n","\n","# Check if data_dir is a real directory\n","if os.path.exists(data_dir) and os.path.isdir(data_dir):\n","    # Get the list of materials in the data_dir folder\n","    subfolders = [item for item in os.listdir(data_dir)\n","                  if os.path.isdir(os.path.join(data_dir, item))]\n","\n","    # Check if there are any subfolders\n","    if subfolders:\n","        # Save the names of the subfolders to the training_materials list\n","        training_materials = subfolders\n","    else:\n","        print(\"No material training datasets found in directory specified by data_dir, preprocessed (normalised, down sampled and split) training materials should be saved into subfolders within this directory, where each subfolder is the name of a training material.\")\n","else:\n","    print(\"Directory specified by data_dir does not seem to exist, please ensure data_dir specifies a folder containing subfolders of processed training datasets for each material.\")\n","\n","# Print the list of training materials if they exist\n","if training_materials:\n","    print(\"Identified training data for materials:\", training_materials)"]},{"cell_type":"markdown","metadata":{},"source":["# CUDA\n","Engage CUDA if Available"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2977,"status":"ok","timestamp":1719412613999,"user":{"displayName":"Ossian Sydow Elias","userId":"08221504421133916868"},"user_tz":-60},"id":"P71KxLw8ElbE","outputId":"4dfbf9e9-886a-43a0-e7aa-78e527d16472"},"outputs":[],"source":["import torch\n","\n","gpu_num = 0\n","cuda_ready = False # Track if CUDA hardware acceleration is engaged\n","\n","if torch.cuda.is_available():\n","    cuda_ready = True\n","    print('CUDA available!')\n","    gpu_num = torch.cuda.device_count()\n","    if (gpu_num < 1):\n","        print('GPU unavailable')\n","    else:\n","        print('GPU num: ', gpu_num)  # Print number of GPUs\n","        for gpu in range(gpu_num):\n","            print('GPU type: ', torch.cuda.get_device_name(gpu))  # Print model of GPU\n","            print('GPU memory: {:.2f} Gbyte'.format(\n","                torch.cuda.get_device_properties(gpu).total_memory /\n","                1e9))  # Print total GPU memory\n","else:\n","    cuda_ready = False\n","    print('CUDA unavailable')\n","\n","# Check if CUDA is available and if so, set the device to GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#device = torch.device(\"cpu\")\n","print(\"System using \", device)"]},{"cell_type":"markdown","metadata":{"id":"7HgpdP0B01VH"},"source":["# Model Training\n","First set base material for transfer learning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":144601,"status":"ok","timestamp":1719412758596,"user":{"displayName":"Ossian Sydow Elias","userId":"08221504421133916868"},"user_tz":-60},"id":"wiuabFEK01VI","outputId":"dc37bf5d-5e39-4c0f-d757-6dd137e85730"},"outputs":[],"source":["base_mat = \"3C90\" # This is the base material used to facilitate the first stage of transfer learning as described in the paper, material with largest training dataset selected by default, set as '' to train each material from scratch\n","model_saved_name = \"model_weights.ckpt\"\n","\n","# Setting training period approproate for compute available\n","if cuda_ready:\n","    epochs = 500\n","    valid_batch_size = 3000\n","else:\n","    epochs = 20\n","    valid_batch_size = 1000\n","\n","from train_model import train_model\n","\n","if base_mat == '':\n","    print('Transfer learning function disabled, each material will train from zero initial weightings.')\n","    for material in training_materials:\n","        train_model(data_dir, material, base_mat, model_saved_name, device, epochs, valid_batch_size)\n","elif base_mat in training_materials: # If base training material has been found in directory of materials\n","    base_model_path = os.path.join(data_dir, base_mat, model_saved_name)\n","    if os.path.exists(base_model_path):\n","        print('Base model used for transfer learning found at:', base_model_path)\n","        for material in training_materials:\n","            if material != base_mat: # Prevents pretrained base model from being unnesscesarily retrained\n","                train_model(data_dir, material, base_mat, model_saved_name, device, epochs, valid_batch_size, verbose=False, load_pretrained=True)\n","    else:\n","        print(f\"No base model of material {base_mat} found to facilitate transfer learning, program will need to train {base_mat} from scratch before fine-tuning for other materials.\")\n","        train_model(data_dir, base_mat, base_mat, model_saved_name, device, epochs, valid_batch_size, verbose=True) # Trains base material from scratch before transferring it to remaining materials\n","        for material in training_materials:\n","            if material != base_mat: # Skips retraining base model\n","                train_model(data_dir, material, base_mat, model_saved_name, device, epochs, valid_batch_size, verbose=False, load_pretrained=True) # Trains remaining materials using base model as starting point 'fine tuning'\n","else:\n","    raise RuntimeError(f\"No training data or pretrained model found for material {base_mat}, check that data directory and base material preference is correctly set in beginning of this cell.\")"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
